{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alecuc/POHMM_RHU_keystroke/blob/main/POHMM_RHU_keystroke.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTk272D3hsOp"
      },
      "source": [
        "import os # Path related\n",
        "import numpy as np # Mathematics\n",
        "from sklearn.metrics import accuracy_score # ACC calc\n",
        "from sklearn.metrics import roc_curve as _roc_curve # EER calc\n",
        "from sklearn.metrics import auc # AUC calc\n",
        "import pandas as pd # Dataset processing\n",
        "import itertools\n",
        "from typing import Optional, Union\n",
        "try:\n",
        "  import pohmm\n",
        "except:\n",
        "  !pip install pohmm\n",
        "import warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p19X2wamkMlq"
      },
      "source": [
        "Path related variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0qaF19RkEfB"
      },
      "source": [
        "ROOT_DIR = os.getcwd()\n",
        "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
        "HMM_DATA_DIR = os.path.join(DATA_DIR, \"hmm\")\n",
        "POHMM_DATA_DIR = os.path.join(DATA_DIR, \"pohmm\")\n",
        "RAW_DATA_DIR = os.path.join(DATA_DIR, \"raw\")\n",
        "RAW_DATASET_FILE = os.path.join(RAW_DATA_DIR, \"keystroke_51.xls\")\n",
        "\n",
        "# POHMM\n",
        "POHMM_ADAPTED_DATASET_FILE = os.path.join(POHMM_DATA_DIR, \"pohmm_keystroke_51_adapted.csv\")\n",
        "POHMM_EVENT_SCORES_DATASET_FILE = os.path.join(POHMM_DATA_DIR, \"pohmm_keystroke_51_event_scores.csv\")\n",
        "POHMM_RAW_SESSION_SCORES_DATASET_FILE = os.path.join(POHMM_DATA_DIR, \"pohmm_keystroke_51_raw_session_scores.csv\")\n",
        "POHMM_NORMALIZED_SESSION_SCORES_DATASET_FILE = os.path.join(POHMM_DATA_DIR,\n",
        "                                                            \"pohmm_keystroke_51_normalized_session_scores.csv\")\n",
        "POHMM_SUMMARY_DATASET_FILE = os.path.join(POHMM_DATA_DIR, \"pohmm_keystroke_51_summary.csv\")\n",
        "\n",
        "# HMM\n",
        "HMM_ADAPTED_DATASET_FILE = os.path.join(HMM_DATA_DIR, \"hmm_keystroke_51_adapted.csv\")\n",
        "HMM_EVENT_SCORES_DATASET_FILE = os.path.join(HMM_DATA_DIR, \"hmm_keystroke_51_event_scores.csv\")\n",
        "HMM_RAW_SESSION_SCORES_DATASET_FILE = os.path.join(HMM_DATA_DIR, \"hmm_keystroke_51_raw_session_scores.csv\")\n",
        "HMM_NORMALIZED_SESSION_SCORES_DATASET_FILE = os.path.join(HMM_DATA_DIR, \"hmm_keystroke_51_normalized_session_scores.csv\")\n",
        "HMM_SUMMARY_DATASET_FILE = os.path.join(HMM_DATA_DIR, \"hmm_keystroke_51_summary.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8QxwubTkO68"
      },
      "source": [
        "Dataset related fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twh-dYqakFcn"
      },
      "source": [
        "ID_FIELD = \"id\"\n",
        "TRIALS_FIELD = \"trials\"\n",
        "USERNAME_FIELD = \"UserName\"\n",
        "PP_FIELD = \"PP\"\n",
        "PR_FIELD = \"PR\"\n",
        "RR_FIELD = \"RR\"\n",
        "RP_FIELD = \"RP\"\n",
        "DATA_FIELD = \"date\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF5j0gUgkQee"
      },
      "source": [
        "Processed dataset related fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVYcq8nkkGsh"
      },
      "source": [
        "FOLD_FIELD = \"fold\"\n",
        "QUERY_USER_FIELD = \"query_user\"\n",
        "QUERY_SESSION_FIELD = \"query_session\"\n",
        "REFERENCE_USER_FIELD = \"reference_user\"\n",
        "SCORE_FIELD = \"score\"\n",
        "NORMALIZED_SCORE_FIELD = \"nscore\"\n",
        "RESULT_FIELD = \"result\"\n",
        "EVENT_INDEX_FIELD = \"event_idx\"\n",
        "EVENT_FIELD = \"event\"\n",
        "STATE_FIELD = \"state\"\n",
        "RANK_FIELD = \"rank\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDkxAdHokSxE"
      },
      "source": [
        "ROC fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdkU6tFOkIvq"
      },
      "source": [
        "ROC_THRESHOLD = \"threshold\"\n",
        "FALSE_ACCEPTANCE_RATE = \"far\"\n",
        "FALSE_REJECTION_RATE = \"frr\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAsua1_O4QO1"
      },
      "source": [
        "Summary fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8TpanYI4Qqv"
      },
      "source": [
        "SESSION_ACCURACY = \"S-ACC\"\n",
        "SESSION_EQUAL_ERROR_RATE = \"S-EER\"\n",
        "USER_ACCURACY = \"U-ACC\"\n",
        "USER_EQUAL_ERROR_RATE = \"U-EER\"\n",
        "AREA_UNDER_ROC_CURVE = \"AUC\"\n",
        "CONTINUOUS_IDENTIFICATION_ACCURACY = \"CIA\"\n",
        "AVERAGE_MAXIMUM_REJECTION_TIME = \"AMRT\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AumUOMnElddU"
      },
      "source": [
        "Continuous verification fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze5LBiqGldzp"
      },
      "source": [
        "PENALTY_FIELD = \"penalty\"\n",
        "CV_THRESHOLD_FIELD = \"threshold\"\n",
        "MAXIMUM_REJECTION_TIME_FIELD = \"mrt\"\n",
        "AVERAGE_MAXIMUM_REJECTION_TIME_FIELD = \"amrt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsbBeo18kTg5"
      },
      "source": [
        "Miscellaneous"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io_hcuKPkKIh"
      },
      "source": [
        "HARDCODED_PASSWORD = \"rhu.university\"\n",
        "MAX_ROWS_PER_USER = 15\n",
        "REFERENCE_FOLD_THRESHOLD = 13"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dCNk1kDkXzp"
      },
      "source": [
        "Setup `numpy` seed to predefined value in order to be able to replicate executions. <br>\n",
        "Set pandas options for the sake of printing a complete `pd.DataFrame` (debug purposes).\n",
        "Get rid of \"invalid value encountered in log\" `RuntimeWarning`(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDTRwhUkkYIn"
      },
      "source": [
        "def setup(seed=1234,\n",
        "          precision=8,\n",
        "          max_columns=None,\n",
        "          max_rows=None,\n",
        "          split_df_print=False) -> None:\n",
        "    \"\"\"\n",
        "    :param seed: numpy seed\n",
        "    :param precision: numpy print precision\n",
        "    :param max_columns: max columns to display in a pd.DataFrame print\n",
        "    :param max_rows: max rows to display in a pd.DataFrame print\n",
        "    :param split_df_print: Split the pd.DataFrame on a new line when printing if the pd.DataFrame is huge (horizontally)?\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    np.set_printoptions(precision=precision)\n",
        "    pd.set_option(\"max_columns\", max_columns)\n",
        "    pd.set_option(\"max_rows\", max_rows)\n",
        "    pd.set_option(\"display.expand_frame_repr\", split_df_print)\n",
        "    warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in log\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZeQpWlIlSz0"
      },
      "source": [
        "Creates a file specified by the `file_and_ext` param and saves `df` content in it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGkvuZMjlTE7"
      },
      "source": [
        "def save_data(df: pd.DataFrame,\n",
        "              file_and_ext: str) -> None:\n",
        "    \"\"\"\n",
        "    :param df: pandas.DataFrame to be saved\n",
        "    :param file_and_ext: Full path and extension of the .csv file which will store the df current content\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    df.to_csv(file_and_ext)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff1PLhn8lbYs"
      },
      "source": [
        "Split a char-separated string into a list containing floating point values contained in the string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt0uDwgjlbqS"
      },
      "source": [
        "def str_to_float_list(s: str,\n",
        "                      c=\";\") -> list:\n",
        "    \"\"\"\n",
        "    :param s: the string to be split\n",
        "    :param c: the character which separates the different values in the string\n",
        "    :return: the list\n",
        "    \"\"\"\n",
        "    return list(map(float, s.split(c)[:-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDLzIX2plnqv"
      },
      "source": [
        "Process rhu university dataset in order to pair every character from the password to its corresponding `PP` - `PR` - `RP` - `RR` values. If `is_pohmm` is `True`, process the dataset for `POHMM` training. Process it for `HMM` otherwise. \n",
        "\n",
        "<br>\n",
        "\n",
        "`PP`, `RP` and `RR` number of values are one less than the total amount of characters in the password: `\"rhu.university\"`.\n",
        "<br>\n",
        "With this in mind, the standard deviation of the said values has been added to the corresponding lists.\n",
        "\n",
        "<br>\n",
        "\n",
        "Globals: <br>\n",
        "`user_map`: map number to users<br>\n",
        "`counter`: count the number of users<br>\n",
        "`trials`: count inputs from a single user<br>\n",
        "\n",
        "<br>\n",
        "\n",
        "`process_row` processes a single row from the input dataset.\n",
        "`preprocess_rhu_university` wraps `process_row` in order to process the whole raw input dataset. Results are saved in `ADAPTED_DATASET_FILE`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17zZAKJvln_7"
      },
      "source": [
        "user_map = {}\n",
        "counter = 0\n",
        "trials = {}\n",
        "\n",
        "\n",
        "def preprocess_rhu_university(raw_dataset_input_file: str,\n",
        "                              is_pohmm: bool) -> None:\n",
        "    \"\"\"\n",
        "    :param raw_dataset_input_file: Full path and extension of the .xls raw dataset file\n",
        "    :param is_pohmm: True -> craft POHMM df or False -> craft HMM df \n",
        "    :return: None\n",
        "    \"\"\"\n",
        "\n",
        "    def process_row(idx_row: (int, pd.Series)) -> Optional[pd.DataFrame]:\n",
        "        \"\"\"\n",
        "        :param idx_row: tuple containing row number and row data\n",
        "        :return: none if the inputs from a single user reached the threshold or\n",
        "                      if one of the fields is invalid\n",
        "                pd.DataFrame containing the processed row if the input is valid\n",
        "        \"\"\"\n",
        "        global counter\n",
        "        _, row = idx_row\n",
        "        user = row[USERNAME_FIELD].lower()\n",
        "\n",
        "        # If the user isn't mapped yet, map it and increment the counter\n",
        "        if user not in user_map:\n",
        "            user_map[user] = counter\n",
        "            trials[user] = 0\n",
        "            counter += 1\n",
        "\n",
        "        # If the number of inputs from a single user reached the threshold,\n",
        "        # abort further processings\n",
        "        if trials[user] == MAX_ROWS_PER_USER:\n",
        "            return None\n",
        "\n",
        "        # Try to process PP, PR, RP, RR fields.\n",
        "        pp_field = str_to_float_list(row[PP_FIELD])\n",
        "        pp_field.insert(0, np.std(pp_field))\n",
        "        rp_field = str_to_float_list(row[RP_FIELD])\n",
        "        rp_field.append(np.std(rp_field))\n",
        "        rr_field = str_to_float_list(row[RR_FIELD])\n",
        "        rr_field.append(np.std(rr_field))\n",
        "        pr_field = str_to_float_list(row[PR_FIELD])\n",
        "\n",
        "        # In case of errors, abort further processings\n",
        "        # if None in pp_field or None in rp_field or None in rr_field:\n",
        "        #    return None\n",
        "\n",
        "        # If the user didn't input all the needed characters\n",
        "        # abort further processings\n",
        "        if len(pp_field) == len(pr_field) == len(HARDCODED_PASSWORD):\n",
        "            trials[user] += 1\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "        # If we reach this, everything went as planned.\n",
        "        # Create and return the processed row as a pd.DataFrame.\n",
        "        return pd.DataFrame.from_dict({\n",
        "            USERNAME_FIELD: user_map[user],\n",
        "            TRIALS_FIELD: row[TRIALS_FIELD],\n",
        "            EVENT_FIELD: list(HARDCODED_PASSWORD) if is_pohmm else np.ones(len(HARDCODED_PASSWORD)),\n",
        "            PP_FIELD: pp_field,\n",
        "            PR_FIELD: pr_field,\n",
        "            RP_FIELD: rp_field,\n",
        "            RR_FIELD: rr_field\n",
        "        })\n",
        "\n",
        "    user_map.clear()\n",
        "    counter = 0\n",
        "    trials.clear()\n",
        "\n",
        "    # Concat all processed rows obtained from process_row\n",
        "    df = pd.concat(map(process_row, pd.read_excel(raw_dataset_input_file).iterrows())).set_index(\n",
        "        [USERNAME_FIELD, TRIALS_FIELD])\n",
        "\n",
        "    # And save the so crafted pd.DataFrame.\n",
        "    save_data(df, POHMM_ADAPTED_DATASET_FILE if is_pohmm else HMM_ADAPTED_DATASET_FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wD4YtDKtDaB"
      },
      "source": [
        "Split the input dataset based on the numpy arrays in the arguments. Further processes it in order to apply a stratified k-fold cross validation.\n",
        "\n",
        "<br>\n",
        "\n",
        "The template is simply filtered. Genuine and impostor are instead processed in order to assign every other user to the current processed user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRJH2uxCtDn8"
      },
      "source": [
        "def split_dataset(df: pd.DataFrame,\n",
        "                  template_reps: np.ndarray,\n",
        "                  genuine_reps: np.ndarray,\n",
        "                  impostor_reps: np.ndarray) -> (pd.DataFrame, pd.DataFrame, pd.DataFrame):\n",
        "    \"\"\"\n",
        "    :param df: pd.DataFrame to be processed\n",
        "    :param template_reps: the numpy array containing which values of a user's single input are taken as a template\n",
        "    :param genuine_reps: the numpy array containing which values of a user's single input are taken as genuine inputs\n",
        "    :param impostor_reps: the numpy array containing which values of a user's single input are taken as impostor inputs\n",
        "    :return: the split dataset in the three parts.\n",
        "    \"\"\"\n",
        "\n",
        "    # Filter based on the input numpy arrays\n",
        "    df_template = df[df.index.get_level_values(1).isin(template_reps)]\n",
        "    df_genuine = df[df.index.get_level_values(1).isin(genuine_reps)]\n",
        "    df_impostor = df[df.index.get_level_values(1).isin(impostor_reps)]\n",
        "\n",
        "    # Setup genuine pd.DataFrame\n",
        "    df_genuine.index.names = [USERNAME_FIELD, TRIALS_FIELD]\n",
        "    df_genuine = df_genuine.reset_index()\n",
        "    df_genuine[QUERY_USER_FIELD] = df_genuine[USERNAME_FIELD]\n",
        "    df_genuine = df_genuine.set_index([USERNAME_FIELD, QUERY_USER_FIELD, TRIALS_FIELD])\n",
        "\n",
        "    # Setup impostor pd.DataFrame\n",
        "    df_impostor.index.names = [USERNAME_FIELD, TRIALS_FIELD]\n",
        "    df_impostor = df_impostor.reset_index()\n",
        "    df_impostor[QUERY_USER_FIELD] = df_impostor[USERNAME_FIELD]\n",
        "    df_impostor = df_impostor.set_index([USERNAME_FIELD, QUERY_USER_FIELD, TRIALS_FIELD])\n",
        "\n",
        "    # Create a comparison row with all other users, for each user\n",
        "    dfs_impostor = []\n",
        "\n",
        "    for user in df.index.get_level_values(0).unique():\n",
        "        df_tmp = df_impostor.drop(user, level=0).reset_index().copy()\n",
        "        df_tmp[USERNAME_FIELD] = user\n",
        "        dfs_impostor.append(df_tmp)\n",
        "\n",
        "    # Add the comparison rows to the impostor pd.DataFrame\n",
        "    df_impostor = pd.concat(dfs_impostor).set_index(\n",
        "        [USERNAME_FIELD, QUERY_USER_FIELD, TRIALS_FIELD])\n",
        "\n",
        "    return df_template, df_genuine, df_impostor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDscM9jaDIR7"
      },
      "source": [
        "Function that takes all the samples from a single user and returns a fitted model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa6VPtN7DImr"
      },
      "source": [
        "def train_model(df: pd.DataFrame) -> pohmm.Pohmm:\n",
        "    \"\"\"\n",
        "    :param df: pandas.DataFrame containing samples from a single user\n",
        "    :return: the fitted model\n",
        "    \"\"\"\n",
        "    emissions = []\n",
        "    for col in df.columns.difference([EVENT_FIELD]):\n",
        "        if col in [PR_FIELD, PP_FIELD, RP_FIELD, RR_FIELD]:\n",
        "            emissions.append((col, 'normal'))\n",
        "        else:\n",
        "            emissions.append((col, 'normal'))\n",
        "\n",
        "    hmm = pohmm.Pohmm(n_hidden_states=2, init_spread=2, thresh=1e-6, max_iter=1000,\n",
        "                      emissions=emissions, smoothing='freq')\n",
        "\n",
        "    hmm.fit_df(list(zip(*df.groupby(level=[0, 1])))[1])\n",
        "    return hmm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NrnY1lLtgoR"
      },
      "source": [
        "Obtain identification and verification results using stratified k-fold cross validation and a model that scores a sample.\n",
        "\n",
        "<br>\n",
        "\n",
        "Creates a scores dataframe with cols: `FOLD_FIELD`, `REFERENCE_USER_FIELD`, `QUERY_USER_FIELD`, `QUERY_SESSION_FIELD`, `EVENT_INDEX_FIELD` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xabFJp1tg5y"
      },
      "source": [
        "def cv_event_scores(fold: (pd.DataFrame, pd.DataFrame, pd.DataFrame)) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    :param fold: the dataset split in reference for the model, genuine users and impostors.\n",
        "    :return scores: the pd.DataFrame containing processed input fold, and a score for each one of the users' session.\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    reference, genuine, impostor = fold\n",
        "    models = {}\n",
        "\n",
        "    # Train a model for each user\n",
        "    for reference_user, reference_data in reference.groupby(level=[0]):\n",
        "        models[reference_user] = train_model(reference_data)\n",
        "\n",
        "    for (reference_user, query_user, query_session), query_data in itertools.chain(genuine.groupby(level=[0, 1, 2]),\n",
        "                                                                                   impostor.groupby(\n",
        "                                                                                       level=[0, 1, 2])):\n",
        "        # Evaluate scores and states for each users (see pohmm source code)\n",
        "        score = models[reference_user].score_events_df(query_data.reset_index(drop=True))\n",
        "        state = models[reference_user].predict_states_df(query_data.reset_index(drop=True))\n",
        "\n",
        "        # Create a pd.DataFrame which contains the processed data\n",
        "        df = pd.DataFrame({FOLD_FIELD: 0,\n",
        "                           REFERENCE_USER_FIELD: reference_user,\n",
        "                           QUERY_USER_FIELD: query_user,\n",
        "                           QUERY_SESSION_FIELD: query_session,\n",
        "                           EVENT_INDEX_FIELD: np.arange(len(query_data)),\n",
        "                           EVENT_FIELD: query_data[EVENT_FIELD].values,\n",
        "                           SCORE_FIELD: score[SCORE_FIELD],\n",
        "                           STATE_FIELD: state[STATE_FIELD],\n",
        "                           },\n",
        "                          columns=[FOLD_FIELD, REFERENCE_USER_FIELD, QUERY_USER_FIELD,\n",
        "                                   QUERY_SESSION_FIELD, EVENT_INDEX_FIELD,\n",
        "                                   EVENT_FIELD, SCORE_FIELD, STATE_FIELD])\n",
        "        scores.append(df)\n",
        "\n",
        "    # Obtain a pd.DataFrame from the scores list and reset its index\n",
        "    scores = pd.concat(scores).reset_index(drop=True)\n",
        "\n",
        "    # Compute the rank field and add it as a column in the scores pd.DataFrame\n",
        "    scores[RANK_FIELD] = scores.groupby([FOLD_FIELD, QUERY_USER_FIELD,\n",
        "                                                QUERY_SESSION_FIELD, EVENT_INDEX_FIELD])[\n",
        "                                    SCORE_FIELD].rank(ascending=False) - 1\n",
        "    return scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFRpE4gVwWck"
      },
      "source": [
        "Normalize session scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8CnMewKwWsD"
      },
      "source": [
        "def normalize_session_scores(session_scores: pd.DataFrame,\n",
        "                             pivot=[FOLD_FIELD, QUERY_USER_FIELD, QUERY_SESSION_FIELD],\n",
        "                             h=2) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    :param session_scores: pd.DataFrame containing session scores\n",
        "    :param pivot: Values which the function will group the dataset by \n",
        "    :param h: stddev stuff\n",
        "    :return: normalized pd.DataFrame\n",
        "    \"\"\"\n",
        "    def _norm(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        :param df: pd.DataFrame which will be normalized\n",
        "        :return: normalized pd.DataFrame\n",
        "        \"\"\"\n",
        "        lower = df[SCORE_FIELD].min()\n",
        "        upper = df[SCORE_FIELD].max()\n",
        "\n",
        "        df[NORMALIZED_SCORE_FIELD] = np.minimum(\n",
        "            np.maximum((df[SCORE_FIELD] - lower) / (upper - lower), 0), 1)\n",
        "        return df\n",
        "\n",
        "    session_scores = session_scores.groupby(pivot).apply(_norm)\n",
        "    return session_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1UANYLdx49E"
      },
      "source": [
        "Prepare session scores in order to calculate its accuracy in the ACC function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkuNnMCcxwPq"
      },
      "source": [
        "def session_identification(session_scores: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    :param session_scores: pd.DataFrame\n",
        "    :return: the ACC-processable pd.DataFrame\n",
        "    \"\"\"\n",
        "    ide = session_scores.groupby([FOLD_FIELD, QUERY_USER_FIELD, QUERY_SESSION_FIELD]).apply(\n",
        "        lambda x: x.iloc[np.argmax(x[SCORE_FIELD].values)][[REFERENCE_USER_FIELD]])\n",
        "    ide.columns = [RESULT_FIELD]\n",
        "    ide = ide.reset_index()\n",
        "    return ide"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqK8PkLsx5SD"
      },
      "source": [
        "See `sklearn.metrics.roc_curve`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2y57g9pxxCM"
      },
      "source": [
        "def roc_curve(y_true: np.ndarray,\n",
        "              y_score: np.ndarray) -> (np.ndarray, np.ndarray, np.ndarray):\n",
        "    \"\"\"\n",
        "    :params and return types: np.ndarray\n",
        "    :return: roc values\n",
        "    \"\"\"\n",
        "    fpr, tpr, thresholds = _roc_curve(y_true, y_score, drop_intermediate=True)\n",
        "    return fpr, 1 - tpr, thresholds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGHkD0PsyQHw"
      },
      "source": [
        "Generate Receiver Operating Characteristic (ROC) curve for each fold and interpolate it to get the same threshold values in each fold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4_8xlxhyQWn"
      },
      "source": [
        "def session_roc(session_scores: pd.DataFrame,\n",
        "                pivot=FOLD_FIELD) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    :param session_scores: pd.DataFrame containing session scores\n",
        "    :param pivot: Values which the function will group the dataset by\n",
        "    :return: Receiver Operating Characteristic (ROC) pd.DataFrame\n",
        "    \"\"\"\n",
        "    # Generate an ROC curve for each fold, ordered by increasing threshold\n",
        "    roc = session_scores.groupby(pivot).apply(\n",
        "        lambda x: pd.DataFrame(np.c_[roc_curve((x[QUERY_USER_FIELD] == x[REFERENCE_USER_FIELD]).values.astype(np.int32),\n",
        "                                               x[NORMALIZED_SCORE_FIELD].values.astype(np.float32))][::-1],\n",
        "                               columns=[FALSE_ACCEPTANCE_RATE, FALSE_REJECTION_RATE, ROC_THRESHOLD]))\n",
        "\n",
        "    # interpolate to get the same threshold values in each fold\n",
        "    thresholds = np.sort(roc[ROC_THRESHOLD].unique())\n",
        "    roc = roc.groupby(level=pivot).apply(lambda x: pd.DataFrame(np.c_[thresholds,\n",
        "                                                                      np.interp(thresholds, x[ROC_THRESHOLD],\n",
        "                                                                            x[FALSE_ACCEPTANCE_RATE]),\n",
        "                                                                      np.interp(thresholds, x[ROC_THRESHOLD],\n",
        "                                                                            x[FALSE_REJECTION_RATE])],\n",
        "                                                                columns=[ROC_THRESHOLD, FALSE_ACCEPTANCE_RATE,\n",
        "                                                                         FALSE_REJECTION_RATE]))\n",
        "    roc = roc.reset_index(level=1, drop=True).reset_index()\n",
        "    return roc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBsOyp6pyv5N"
      },
      "source": [
        "Obtain rank-n classification accuracy for each fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKBhh6pAywJD"
      },
      "source": [
        "def ACC(ide: pd.DataFrame) -> float:\n",
        "    \"\"\"\n",
        "    :param ide: the identification pd.DataFrame on which classification accuracy needs to be obtained\n",
        "    :return: accuracy score calculated by scikit learn module.\n",
        "    \"\"\"\n",
        "    return accuracy_score(ide[QUERY_USER_FIELD].values, ide[RESULT_FIELD].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9LKsDr7ywiE"
      },
      "source": [
        "Obtain the Equal Error Rate for one fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBDJfN1Ayw8W"
      },
      "source": [
        "def EER(roc: pd.DataFrame) -> float:\n",
        "    \"\"\"\n",
        "    :param roc: the Receiver Operating Characteristic pd.DataFrame\n",
        "    :return: Equal Error Rate float\n",
        "    \"\"\"\n",
        "    far, frr = roc[FALSE_ACCEPTANCE_RATE].values, roc[FALSE_REJECTION_RATE].values\n",
        "\n",
        "    def perp(a: np.ndarray) -> np.ndarray:\n",
        "        b = np.empty_like(a)\n",
        "        b[0] = -a[1]\n",
        "        b[1] = a[0]\n",
        "        return b\n",
        "\n",
        "    def seg_intersect(a1: np.array,\n",
        "                      a2: np.array,\n",
        "                      b1: np.array,\n",
        "                      b2: np.array) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        :param a1: line segment endpoint for a segment\n",
        "        :param a2: line segment endpoint for a segment\n",
        "        :param b1: line segment endpoint for b segment\n",
        "        :param b2: line segment endpoint for b segment\n",
        "        :return: segment intersection between a and b\n",
        "        \"\"\"\n",
        "        da = a2 - a1\n",
        "        db = b2 - b1\n",
        "        dp = a1 - b1\n",
        "        dap = perp(da)\n",
        "        denom = np.dot(dap, db)\n",
        "        num = np.dot(dap, dp)\n",
        "        return (num / denom) * db + b1\n",
        "\n",
        "    d = far <= frr\n",
        "    idx = np.diff(d).nonzero()[0][0]\n",
        "    return seg_intersect(np.array([idx, far[idx]]),\n",
        "                         np.array([idx + 1, far[idx + 1]]),\n",
        "                         np.array([idx, frr[idx]]),\n",
        "                         np.array([idx + 1, frr[idx + 1]]))[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UdpzRc-bilD"
      },
      "source": [
        "Prepare session scores in order to identificate each event"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkIwnlyrbi38"
      },
      "source": [
        "def continuous_identification(scores: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    :param scores: pd.DataFrame containing scores\n",
        "    :return: the ACC-processable pd.DataFrame \n",
        "    \"\"\"\n",
        "    ide = scores.groupby([FOLD_FIELD, QUERY_USER_FIELD, QUERY_SESSION_FIELD, EVENT_INDEX_FIELD]).apply(\n",
        "        lambda x: x.iloc[np.argmax(x[SCORE_FIELD].values)][[REFERENCE_USER_FIELD]])\n",
        "    ide.columns = [RESULT_FIELD]\n",
        "    ide = ide.reset_index()\n",
        "    return ide"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3-xxDazbjH_"
      },
      "source": [
        "Continuous verification is enforced through a penalty function in which each new keystroke incurs a non-negative penalty within a sliding window. The penalty at any given time can be thought of as the inverse of trust. As behavior becomes more consistent with the model, the cumulative penalty within the window can decrease, and as it becomes more dissimilar, the penalty increases. The user is rejected if the cumulative penalty within the sliding window exceeds a threshold. The threshold is chosen for each sam\u0002ple such that the genuine user is never rejected, analogous to a 0% FRR in static verification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9wAjcbObjbB"
      },
      "source": [
        "def scores_penalty(scores: pd.DataFrame,\n",
        "                   penalty_fun='sum',\n",
        "                   window=25) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    :param scores: pd.DataFrame containing scores\n",
        "    :param penalty_fun: the function which will be used to calculate penalty\n",
        "    :param window: sliding window threshold \n",
        "    :return: pd.DataFrame containing penalties\n",
        "    \"\"\"\n",
        "\n",
        "    def _penalty(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        :param df: pd.DataFrame containing a row with a score\n",
        "        :return: pd.DataFrame containing penalty (for one score)\n",
        "        \"\"\"\n",
        "        if penalty_fun == 'sum':\n",
        "            p = df[RANK_FIELD].rolling(window=window, center=False).sum()\n",
        "            p[:window] = df[RANK_FIELD].values[:window].cumsum()\n",
        "        elif penalty_fun == 'sumexp':\n",
        "            p = (np.exp(df[RANK_FIELD]) - 1).rolling(window=window, center=False).sum()\n",
        "            p[:window] = (np.exp(df[RANK_FIELD]) - 1)[:window].cumsum()\n",
        "\n",
        "        df[PENALTY_FIELD] = p\n",
        "        return df\n",
        "\n",
        "    penalty = scores.copy().groupby([FOLD_FIELD, REFERENCE_USER_FIELD, QUERY_USER_FIELD, QUERY_SESSION_FIELD]).apply(_penalty)\n",
        "    return penalty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HImuZ-3ybjof"
      },
      "source": [
        "Calculate area under the ROC curve (See `scikitlearn.metrics.auc`)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4C9f7ChbkCd"
      },
      "source": [
        "def AUC(roc: pd.DataFrame) -> float:\n",
        "    \"\"\"\n",
        "    :param roc: the Receiver Operating Characteristic pd.DataFrame\n",
        "    \"\"\"\n",
        "    return auc(roc[FALSE_REJECTION_RATE].values, roc[FALSE_ACCEPTANCE_RATE].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihlm8rv6bpFL"
      },
      "source": [
        "Determine the maximum lockout time for each impostor/query sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M29SN8SbpW3"
      },
      "source": [
        "def continuous_verification(penalty: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    :param penalty: pd.DataFrame containing penalties\n",
        "    :return: continuous verification results as pd.DataFrame\n",
        "    \"\"\"\n",
        "    genuine_idx = penalty[REFERENCE_USER_FIELD] == penalty[QUERY_USER_FIELD]\n",
        "    genuine = penalty[genuine_idx]\n",
        "    lockout = genuine.groupby([QUERY_USER_FIELD, QUERY_SESSION_FIELD]).max()[[PENALTY_FIELD]]\n",
        "    lockout = pd.DataFrame(lockout)\n",
        "    lockout.columns = [CV_THRESHOLD_FIELD]\n",
        "\n",
        "    impostor = penalty[~genuine_idx]\n",
        "\n",
        "    def _mrt(df: pd.DataFrame) -> Union[np.ndarray, int]:\n",
        "        \"\"\"\n",
        "        :param df: pd.DataFrame containing a row with a penalty\n",
        "        :return: np.ndarray containing maximum rejection time\n",
        "        \"\"\"\n",
        "        thresh = lockout.loc[tuple(df.iloc[0][[QUERY_USER_FIELD, QUERY_SESSION_FIELD]].values)].squeeze()\n",
        "        #thresh = 645\n",
        "        reject = (df[PENALTY_FIELD] > thresh)\n",
        "        return np.where(reject)[0].min() if reject.any() else len(reject)\n",
        "\n",
        "    mrt = impostor.groupby([REFERENCE_USER_FIELD, QUERY_USER_FIELD, QUERY_SESSION_FIELD]).apply(_mrt).reset_index()\n",
        "    mrt.columns = [REFERENCE_USER_FIELD, QUERY_USER_FIELD, QUERY_SESSION_FIELD, MAXIMUM_REJECTION_TIME_FIELD]\n",
        "\n",
        "    amrt = mrt.groupby([QUERY_USER_FIELD, QUERY_SESSION_FIELD])[MAXIMUM_REJECTION_TIME_FIELD].mean()\n",
        "    amrt.columns = [AVERAGE_MAXIMUM_REJECTION_TIME_FIELD]\n",
        "\n",
        "    results = pd.concat([amrt, lockout], axis=1).reset_index().rename(columns={MAXIMUM_REJECTION_TIME_FIELD: AVERAGE_MAXIMUM_REJECTION_TIME_FIELD})\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4RKU-uUzqPQ"
      },
      "source": [
        "Obtain results for a given dataset and features conditioned on the event column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGEenMpzzqf-"
      },
      "source": [
        "def dataset_classification_results(is_pohmm: bool) -> None:\n",
        "    \"\"\"\n",
        "    :param is_pohmm: True -> train POHMM or False -> train HMM \n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    # Load the preprocessed dataset\n",
        "    df = pd.read_csv(POHMM_ADAPTED_DATASET_FILE if is_pohmm else HMM_ADAPTED_DATASET_FILE, index_col=[0, 1])\n",
        "\n",
        "    # Create the validation folds\n",
        "    reference_section = np.arange(1, REFERENCE_FOLD_THRESHOLD)\n",
        "    genuine_section = np.arange(REFERENCE_FOLD_THRESHOLD, MAX_ROWS_PER_USER + 1)\n",
        "    impostor_section = np.arange(REFERENCE_FOLD_THRESHOLD, MAX_ROWS_PER_USER + 1)\n",
        "    fold = split_dataset(df, reference_section, genuine_section, impostor_section)\n",
        "\n",
        "    # Calculate scores\n",
        "    scores = cv_event_scores(fold)\n",
        "    save_data(scores, POHMM_EVENT_SCORES_DATASET_FILE if is_pohmm else HMM_EVENT_SCORES_DATASET_FILE)\n",
        "\n",
        "    # Aggregate the event scores within each session\n",
        "    session_scores = scores.groupby([FOLD_FIELD, REFERENCE_USER_FIELD,\n",
        "                                     QUERY_USER_FIELD, QUERY_SESSION_FIELD])[\n",
        "        SCORE_FIELD].sum().reset_index()\n",
        "    save_data(session_scores,\n",
        "              POHMM_RAW_SESSION_SCORES_DATASET_FILE if is_pohmm else HMM_RAW_SESSION_SCORES_DATASET_FILE)\n",
        "\n",
        "    # Normalize the session scores\n",
        "    session_scores = normalize_session_scores(session_scores)\n",
        "    save_data(session_scores,\n",
        "              POHMM_NORMALIZED_SESSION_SCORES_DATASET_FILE if is_pohmm else HMM_NORMALIZED_SESSION_SCORES_DATASET_FILE)\n",
        "\n",
        "    # Session and continuous identification, verification results\n",
        "    session_ide = session_identification(session_scores)\n",
        "    session_ver = session_roc(session_scores)\n",
        "\n",
        "    continuous_ide = continuous_identification(scores)  # Identification of each event\n",
        "    penalty = scores_penalty(scores)\n",
        "    continuous_ver = continuous_verification(penalty)  # Minimum rejection time\n",
        "\n",
        "    # Summarize\n",
        "    session_acc = session_ide.groupby(FOLD_FIELD).apply(ACC).describe()\n",
        "    session_eer = session_ver.groupby(FOLD_FIELD).apply(EER).describe()\n",
        "    session_auc = session_ver.groupby(FOLD_FIELD).apply(AUC).describe()\n",
        "\n",
        "    # User-dependent EER is obtained by deriving an ROC curve for each user\n",
        "    user_eer = session_roc(session_scores, pivot=REFERENCE_USER_FIELD).groupby(REFERENCE_USER_FIELD).apply(\n",
        "        EER).describe()\n",
        "    user_acc = session_ide.groupby(QUERY_USER_FIELD).apply(ACC).describe()\n",
        "\n",
        "    # Summarize continuous results, CI by session\n",
        "    continuous_acc = continuous_ide.groupby([QUERY_USER_FIELD, QUERY_SESSION_FIELD]).apply(ACC).describe()\n",
        "\n",
        "    # Maximum lockout time, averaged for each session (against all reference users), CI by session\n",
        "    continuous_amrt = continuous_ver[AVERAGE_MAXIMUM_REJECTION_TIME_FIELD].describe()\n",
        "\n",
        "    summary = pd.concat([session_acc, user_acc, session_eer, user_eer, session_auc, continuous_acc, continuous_amrt],\n",
        "                        axis=1)\n",
        "\n",
        "    summary.columns = [SESSION_ACCURACY,\n",
        "                       USER_ACCURACY,\n",
        "                       SESSION_EQUAL_ERROR_RATE,\n",
        "                       USER_EQUAL_ERROR_RATE,\n",
        "                       AREA_UNDER_ROC_CURVE,\n",
        "                       CONTINUOUS_IDENTIFICATION_ACCURACY,\n",
        "                       AVERAGE_MAXIMUM_REJECTION_TIME]\n",
        "    print(summary)\n",
        "    save_data(summary, POHMM_SUMMARY_DATASET_FILE if is_pohmm else HMM_SUMMARY_DATASET_FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dmx7KK4E_dQ5"
      },
      "source": [
        "main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56i-MwfC_dji",
        "outputId": "c45dcde3-c256-4c5f-e9f9-7bf35f1a0869"
      },
      "source": [
        "# Setup\n",
        "setup()\n",
        "\n",
        "##### POHMM #####\n",
        "# Preprocess raw dataset\n",
        "preprocess_rhu_university(RAW_DATASET_FILE, is_pohmm=True)\n",
        "\n",
        "# Classify dataset and save results\n",
        "print('-'*37 + \" POHMM \" + '-'*37)\n",
        "dataset_classification_results(is_pohmm=True)\n",
        "\n",
        "##### HMM #####\n",
        "# Preprocess raw dataset\n",
        "preprocess_rhu_university(RAW_DATASET_FILE, is_pohmm=False)\n",
        "\n",
        "# Classify dataset and save results\n",
        "print('\\n' + '-'*38 + \" HMM \" + '-'*38)\n",
        "dataset_classification_results(is_pohmm=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------- POHMM -------------------------------------\n",
            "          S-ACC      U-ACC     S-EER      U-EER       AUC         CIA        AMRT\n",
            "count  1.000000  51.000000  1.000000  51.000000  1.000000  151.000000  151.000000\n",
            "mean   0.708609   0.712418  0.053377   0.031142  0.015207    0.216651    3.880000\n",
            "std         NaN   0.333464       NaN   0.065473       NaN    0.204942    2.411958\n",
            "min    0.708609   0.000000  0.053377   0.000000  0.015207    0.000000    0.040000\n",
            "25%    0.708609   0.666667  0.053377   0.000000  0.015207    0.071429    2.100000\n",
            "50%    0.708609   0.666667  0.053377   0.006757  0.015207    0.142857    3.840000\n",
            "75%    0.708609   1.000000  0.053377   0.027027  0.015207    0.285714    5.090000\n",
            "max    0.708609   1.000000  0.053377   0.333333  0.015207    0.928571   12.520000\n",
            "\n",
            "-------------------------------------- HMM --------------------------------------\n",
            "          S-ACC      U-ACC     S-EER      U-EER       AUC         CIA        AMRT\n",
            "count  1.000000  51.000000  1.000000  51.000000  1.000000  151.000000  151.000000\n",
            "mean   0.317881   0.313725  0.160927   0.130615  0.090743    0.123463    6.335762\n",
            "std         NaN   0.413182       NaN   0.137327       NaN    0.169219    3.041962\n",
            "min    0.317881   0.000000  0.160927   0.000000  0.090743    0.000000    0.140000\n",
            "25%    0.317881   0.000000  0.160927   0.020270  0.090743    0.000000    4.640000\n",
            "50%    0.317881   0.000000  0.160927   0.074324  0.090743    0.071429    6.420000\n",
            "75%    0.317881   0.666667  0.160927   0.206081  0.090743    0.178571    7.920000\n",
            "max    0.317881   1.000000  0.160927   0.666667  0.090743    0.714286   13.740000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}